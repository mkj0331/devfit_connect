{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c2e82b0",
   "metadata": {},
   "source": [
    "# Wanted Crawling\n",
    "{ \"job_profile_id\": ,\n",
    "  \"회사명\": \"글리티\",\n",
    "  \"직무\": \"마메드네 Backend Engineer (3년 이상)\",\n",
    "  \"포지션 상세\": [],\n",
    "  \"주요업무\": [],\n",
    "  \"자격요건\": [],\n",
    "  \"우대사항\": [],\n",
    "  \"혜택 및 복지\": [],\n",
    "  \"채용 전형\": [],\n",
    "  \"마감일\": \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd797d2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "It looks like you are using Playwright Sync API inside the asyncio loop.\nPlease use the Async API instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 78\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m html\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m### 크롤링 실행\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m job_ids \u001b[38;5;241m=\u001b[39m \u001b[43mget_job_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m job_id \u001b[38;5;129;01min\u001b[39;00m job_ids:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m크롤링: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m, in \u001b[0;36mget_job_ids\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_job_ids\u001b[39m():\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m sync_playwright() \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m     22\u001b[0m         browser \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mchromium\u001b[38;5;241m.\u001b[39mlaunch(headless\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m         page \u001b[38;5;241m=\u001b[39m browser\u001b[38;5;241m.\u001b[39mnew_page()\n",
      "File \u001b[1;32mc:\\Users\\SSAFY\\miniforge3\\envs\\ai_env\\lib\\site-packages\\playwright\\sync_api\\_context_manager.py:47\u001b[0m, in \u001b[0;36mPlaywrightContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_own_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[1;32m---> 47\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Error(\n\u001b[0;32m     48\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"It looks like you are using Playwright Sync API inside the asyncio loop.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03mPlease use the Async API instead.\"\"\"\u001b[39;00m\n\u001b[0;32m     50\u001b[0m             )\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;66;03m# Create a new fiber for the protocol dispatcher. It will be pumping events\u001b[39;00m\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;66;03m# until the end of times. We will pass control to that fiber every time we\u001b[39;00m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;66;03m# block while waiting for a response.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgreenlet_main\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mError\u001b[0m: It looks like you are using Playwright Sync API inside the asyncio loop.\nPlease use the Async API instead."
     ]
    }
   ],
   "source": [
    "from playwright.sync_api import sync_playwright\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "### 개발 직군 공고 상세 페이지 가져오기 ###\n",
    "\n",
    "# 개발 직군 공고들 url\n",
    "LIST_URL = \"https://www.wanted.co.kr/wdlist/518?country=kr&job_sort=job.popularity_order&years=-1&locations=all\"\n",
    "\n",
    "# url의 hash 반환(primary key job id 설정 위함)\n",
    "import hashlib\n",
    "def make_job_profile_id(url: str) -> str:\n",
    "    return hashlib.sha256(url.encode()).hexdigest()[:16]\n",
    "\n",
    "\n",
    "# 개발 직군 공고 url의 id 가져오기\n",
    "def get_job_ids():\n",
    "    with sync_playwright() as p:\n",
    "        browser = p.chromium.launch(headless=False)\n",
    "        page = browser.new_page()\n",
    "        page.goto(LIST_URL, wait_until=\"networkidle\")\n",
    "\n",
    "        # 스크롤 여러 번 내려서 카드 로드(횟수 지정)\n",
    "        for _ in range(1):\n",
    "            page.mouse.wheel(0, 3000)\n",
    "            time.sleep(1.5)\n",
    "\n",
    "        html = page.content()\n",
    "        browser.close()\n",
    "\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    job_ids = []\n",
    "\n",
    "    for a in soup.select(\"div[data-cy='job-card'] a[href^='/wd/']\"):\n",
    "        href = a.get(\"href\")   # /wd/328431\n",
    "        job_id = href.split(\"/\")[-1]\n",
    "        job_ids.append(job_id)\n",
    "\n",
    "    return list(set(job_ids))   # 중복 제거\n",
    "\n",
    "\n",
    "# 특정 공고의 elements 가져오기\n",
    "def crawl_one_job(job_id):\n",
    "    URL = f\"https://www.wanted.co.kr/wd/{job_id}\"\n",
    "\n",
    "    with sync_playwright() as p:\n",
    "        browser = p.chromium.launch(headless=True)\n",
    "        context = browser.new_context(\n",
    "            user_agent=(\n",
    "                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "            ),\n",
    "            locale=\"ko-KR\"\n",
    "        )\n",
    "        page = context.new_page()\n",
    "        page.goto(URL, wait_until=\"domcontentloaded\", timeout=60000)\n",
    "\n",
    "        try:\n",
    "            # 우대사항 등 안보이는 것까지 가져오도록\n",
    "            page.get_by_role(\"button\", name=\"상세 정보 더 보기\").click()\n",
    "            page.wait_for_timeout(1500)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        html = page.content()\n",
    "        browser.close()\n",
    "\n",
    "    return html\n",
    "\n",
    "\n",
    "### 크롤링 실행\n",
    "\n",
    "job_ids = get_job_ids()\n",
    "\n",
    "for job_id in job_ids:\n",
    "    print(f\"크롤링: {job_id}\")\n",
    "\n",
    "    URL = f\"https://www.wanted.co.kr/wd/{job_id}\"\n",
    "    job_profile_id = make_job_profile_id(URL) # url hash\n",
    "\n",
    "    html = crawl_one_job(job_id)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # 회사명\n",
    "    company_name = soup.select_one(\".JobHeader_JobHeader__Tools__Company__Link__NoBQI\")\n",
    "    company_name_text = company_name.get_text(\"\\n\", strip=True) if company_name else \"\"\n",
    "\n",
    "    # 직무\n",
    "    job_name = soup.select_one('.wds-58fmok')\n",
    "    job_name_text = job_name.get_text('\\n', strip=True)\n",
    "\n",
    "    # 본문(포지션 상세, 자격요건, ...)\n",
    "    article = soup.select_one(\".JobDescription_JobDescription__s2Keo\")\n",
    "    article_text = article.get_text(\"\\n\", strip=True) if article else \"\"\n",
    "\n",
    "    # 마감일\n",
    "    deadline = soup.select_one(\".JobDueTime_JobDueTime__yvhtg\")\n",
    "    deadline_text = deadline.get_text(\"\\n\", strip=True) if deadline else \"\"\n",
    "\n",
    "    full_text = article_text + f\"\\n{deadline_text}\"\n",
    "\n",
    "\n",
    "    \n",
    "    # 파싱한 내용 중에 원하는 문구 사이의 내용들 추출\n",
    "    def extract_section(text, start, end=None):\n",
    "        if end:\n",
    "            pattern = rf\"{start}\\n(.*?)(?=\\n{end})\"\n",
    "        else:\n",
    "            pattern = rf\"{start}\\n(.*)\"\n",
    "\n",
    "        match = re.search(pattern, text, re.S)\n",
    "        return match.group(1).strip() if match else None\n",
    "\n",
    "    #  • 기준으로 리스트화\n",
    "    def split_bullets(section_text):\n",
    "        if not section_text:\n",
    "            return []\n",
    "        return [line.strip(\" •\") for line in section_text.split(\"\\n\") if line.strip()]\n",
    "\n",
    "\n",
    "    data = {\n",
    "        \"job_profile_id\": job_profile_id,\n",
    "        \"회사명\": company_name_text,\n",
    "        \"직무\": job_name_text,\n",
    "        \"포지션 상세\": split_bullets(\n",
    "            extract_section(full_text, \"포지션 상세\", \"주요업무\")\n",
    "        ),\n",
    "        \"주요업무\": split_bullets(\n",
    "            extract_section(full_text, \"주요업무\", \"자격요건\")\n",
    "        ),\n",
    "        \"자격요건\": split_bullets(\n",
    "            extract_section(full_text, \"자격요건\", \"우대사항\")\n",
    "        ),\n",
    "        \"우대사항\": split_bullets(\n",
    "            extract_section(full_text, \"우대사항\", \"혜택 및 복지\")\n",
    "        ),\n",
    "        \"혜택 및 복지\": split_bullets(\n",
    "            extract_section(full_text, \"혜택 및 복지\", \"채용 전형\")\n",
    "        ),\n",
    "        \"채용 전형\": split_bullets(\n",
    "            extract_section(full_text, \"채용 전형\", \"마감일\")\n",
    "        ),\n",
    "        \"마감일\": extract_section(full_text, \"마감일\")\n",
    "    }\n",
    "\n",
    "    ### output/회사명.json 경로로 json 파일 로딩\n",
    "    output_dir = \"output\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    output_path = os.path.join(output_dir, f\"{company_name_text}.json\")\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"JSON 저장 완료: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

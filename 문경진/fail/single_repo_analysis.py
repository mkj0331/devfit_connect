import os
import json
from typing import List, Dict
from openai import OpenAI
from dotenv import load_dotenv
load_dotenv()

# ==============================
# 1. ì„¤ì •
# ==============================
OWNER = "thstmddns"
REPO = "NaturalProject"

BASE_DIR = r"C:\Users\SSAFY\Desktop\S14P11B111\ë¬¸ê²½ì§„\github_crawl"
SUMMARY_DIR = os.path.join(BASE_DIR, "summary")
REPO_SUMMARY_DIR = os.path.join(SUMMARY_DIR, "repo_divided_summary")
COMMIT_SUMMARY_PATH = os.path.join(
    SUMMARY_DIR, "commit_summary", f"{OWNER}_{REPO}_commit_summary.json"
)

MODEL_NAME = "gpt-4o-mini"

client = OpenAI(
    api_key=os.getenv("GMS_API_KEY"),
    base_url=os.getenv("GMS_BASE_URL")
)

# ==============================
# 2. ìš”ì•½ íŒŒì¼ ë¡œë“œ
# ==============================

def load_repo_file_summaries(summary_dir: str) -> List[Dict]:
    summaries = []

    for filename in os.listdir(summary_dir):
        if not filename.endswith(".json"):
            continue

        path = os.path.join(summary_dir, filename)
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
            summaries.append(data)

    return summaries


def load_commit_style_summary(path: str) -> Dict:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

# ==============================
# 3. ì‚¬ìš©ì ì°¸ê³  í…ìŠ¤íŠ¸
# ==============================
user_text_for_analysis = "ë‚˜ëŠ” ì´ í”„ë¡œì íŠ¸ì—ì„œ AI ì—­í•  ì „ë°˜ì„ ë§¡ì•˜ì–´."

# ==============================
# 4. LLM ì…ë ¥ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
# ==============================

def build_prompt(repo_summaries, commit_summary):
    return f"""
ë„ˆëŠ” **ê°œë°œì ë ˆí¬ì§€í† ë¦¬ ì¢…í•© ë¶„ì„ AI**ë‹¤.

ì•„ë˜ì— ì œê³µëœ:
- **íŒŒì¼ ë‹¨ìœ„ ì½”ë“œ ìš”ì•½ ì •ë³´**
- **ì»¤ë°‹ ë©”ì‹œì§€ ê¸°ë°˜ ê°œë°œ ìŠ¤íƒ€ì¼ ìš”ì•½**
- **ì‚¬ìš©ìê°€ ì œê³µí•œ ë¶„ì„ ì°¸ê³  í…ìŠ¤íŠ¸**

ë¥¼ ì¢…í•©í•˜ì—¬,
ì‚¬ìš©ìì—ê²Œ ì•„ë˜ 5ê°€ì§€ë¥¼ **ëª…í™•í•˜ê³  êµ¬ì¡°ì ìœ¼ë¡œ ë¶„ì„**í•´ì„œ ì œê³µí•˜ë¼.

### ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ì¶œë ¥ ê·œì¹™
- JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥
- ê° í•­ëª©ì€ ë°˜ë“œì‹œ ì œê³µëœ ìš”ì•½ ì •ë³´ì— ê·¼ê±°í•  ê²ƒ
- í”„ë ˆì„ì›Œí¬, ë¼ì´ë¸ŒëŸ¬ë¦¬, ê¸°ìˆ ëª…ì€ ì˜ì–´ ì›ë¬¸ ìœ ì§€
- ì„œìˆ í˜• ì„¤ëª…ì€ í•œêµ­ì–´ë¡œ ì‘ì„±

---

## ë¶„ì„ í•­ëª©

1. **ì‚¬ìš© ê¸°ìˆ  / ë¼ì´ë¸ŒëŸ¬ë¦¬**
    - ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” í•µì‹¬ì¸ ìƒìœ„ 5ê°œë§Œ ì„ ì •
2. **í˜‘ì—… ë° ê°œë°œ ìŠ¤íƒ€ì¼ ë¶„ì„**
3. **í”„ë¡œì íŠ¸ ì£¼ì œ**
4. **í•µì‹¬ ê¸°ëŠ¥ ë° ì–´í•„ í¬ì¸íŠ¸**
   - ê´€ë ¨ íŒŒì¼ ê²½ë¡œ í¬í•¨
5. **ê°œì„  ë°©í–¥ ì œì•ˆ**
   - ì‚¬ìš©ì ì—­í•  ê³ ë ¤

---

## ì‚¬ìš©ì ì œê³µ ë¶„ì„ ì°¸ê³  í…ìŠ¤íŠ¸
{user_text_for_analysis}

---

## íŒŒì¼ ë‹¨ìœ„ ì½”ë“œ ìš”ì•½
{json.dumps(repo_summaries, ensure_ascii=False)}

---

## ì»¤ë°‹ ê¸°ë°˜ ê°œë°œ ìŠ¤íƒ€ì¼ ìš”ì•½
{json.dumps(commit_summary, ensure_ascii=False)}

---

## ì¶œë ¥ ì˜ˆì‹œ(JSON)
{{
  "tech_stack": {{
    "frameworks": [],
    "libraries": []
  }},
  "collaboration_analysis": {{
    "collaboration": "",
    "development_style": "",
    "developer_traits": ""
  }},
  "project_domain": "",
  "key_features": [
    {{
      "feature": "",
      "description": "",
      "related_code": []
    }}
  ],
  "improvement_suggestions": [
    {{
      "area": "",
      "suggestion": "",
      "reason": ""
    }}
  ]
}}
"""

# ==============================
# 5. LLM í˜¸ì¶œ
# ==============================

def analyze_with_llm(prompt: str):
    response = client.responses.create(
        model=MODEL_NAME,
        input=prompt,
        temperature=0.2
    )
    return response.output_text


# ==============================
# 6. Github apië¡œ í•´ë‹¹ ë ˆí¬ì—ì„œ language ì‚¬ìš© ì´ë ¥ ê°€ì ¸ì˜¤ê¸°
# ==============================
PROGRAMMING_LANGUAGES = {
    "Python", "Java", "JavaScript", "TypeScript",
    "C", "C++", "C#", "Go", "Rust",
    "Kotlin", "Swift",
    "PHP", "Ruby",
    "R",
    "Scala",
    "MATLAB",
    "Dart"
}


def extract_main_languages(languages_raw, whitelist):
    filtered = {
        lang: bytes_
        for lang, bytes_ in languages_raw.items()
        if lang in whitelist
    }

    sorted_langs = sorted(
        filtered.items(),
        key=lambda x: x[1],
        reverse=True
    )

    return [lang for lang, _ in sorted_langs]

import requests
import os

def fetch_repo_languages(owner: str, repo: str, github_token: str | None = None) -> dict:
    """
    GitHub REST APIë¥¼ ì‚¬ìš©í•´ ë ˆí¬ì˜ ì–¸ì–´ë³„ ì‚¬ìš©ëŸ‰(bytes)ì„ ê°€ì ¸ì˜¨ë‹¤.
    ë°˜í™˜ê°’ ì˜ˆ:
    {
        "Python": 27171,
        "C": 1005230,
        ...
    }
    """
    url = f"https://api.github.com/repos/{owner}/{repo}/languages"

    headers = {
        "Accept": "application/vnd.github+json"
    }

    if github_token:
        headers["Authorization"] = f"Bearer {github_token}"

    response = requests.get(url, headers=headers, timeout=10)
    response.raise_for_status()

    return response.json()

GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")

languages_raw = fetch_repo_languages(
    owner=OWNER,
    repo=REPO,
    github_token=GITHUB_TOKEN
)


languages = extract_main_languages(
    languages_raw,
    PROGRAMMING_LANGUAGES
)

import re

def safe_json_loads(llm_output: str) -> dict:
    """
    LLM ì¶œë ¥ì—ì„œ JSON ê°ì²´ë§Œ ì¶”ì¶œí•˜ì—¬ dictë¡œ ë³€í™˜
    """
    if not llm_output or not llm_output.strip():
        raise ValueError("LLM ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    # ì½”ë“œë¸”ë¡ ì œê±°
    cleaned = re.sub(r"```(?:json)?", "", llm_output).strip()

    # JSON ì‹œì‘/ë ìœ„ì¹˜ ì°¾ê¸°
    start = cleaned.find("{")
    end = cleaned.rfind("}")

    if start == -1 or end == -1:
        raise ValueError("LLM ì‘ë‹µì—ì„œ JSON ê°ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    json_str = cleaned[start:end + 1]

    return json.loads(json_str)



# ==============================
# 7. ì‹¤í–‰
# ==============================

if __name__ == "__main__":
    print("ğŸ“‚ íŒŒì¼ ìš”ì•½ ë¡œë“œ ì¤‘...")
    repo_summaries = load_repo_file_summaries(REPO_SUMMARY_DIR)

    print("ğŸ“‚ ì»¤ë°‹ ìš”ì•½ ë¡œë“œ ì¤‘...")
    commit_summary = load_commit_style_summary(COMMIT_SUMMARY_PATH)

    print("ğŸ§  LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±...")
    prompt = build_prompt(repo_summaries, commit_summary)
    print(f"Prompt length: {len(prompt)}")

    print("ğŸš€ AI ì¢…í•© ë¶„ì„ ìš”ì²­ ì¤‘...")
    raw_result = analyze_with_llm(prompt)

    result = safe_json_loads(raw_result)

    result["tech_stack"]["languages"] = languages # apië¡œ ê°€ì ¸ì˜¨ ì–¸ì–´ ì‚¬ìš©ëŸ‰ ì •ë ¬í•œê±°

    # PK ì„¤ì •
    repo_analysis_id = f"{OWNER}/{REPO}"    
    result["repo_analysis_id"] = repo_analysis_id 

    save_path = r"C:\Users\SSAFY\Desktop\S14P11B111\ë¬¸ê²½ì§„\single_repo_analysis"
    output_path = os.path.join(save_path, f"{OWNER}_{REPO}_single_analysis.json")
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"âœ… ìµœì¢… ë¶„ì„ ì™„ë£Œ!\nê²°ê³¼ ì €ì¥ ìœ„ì¹˜:\n{output_path}")
